{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "13cefc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from sklearn import svm, metrics\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error, roc_auc_score, recall_score, roc_curve, auc, cohen_kappa_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "import seaborn as sns\n",
    "from imblearn.datasets import make_imbalance\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import os\n",
    "\n",
    "\n",
    "df3 = pd.read_excel('/Users/dawidarakelyan/Desktop/Capstone final/testing_findal.xlsx')\n",
    "df3 = pd.DataFrame(df3)\n",
    "\n",
    "# Drop not needed columns\n",
    "df3 = df3.drop(['Unnamed: 0', 'id', 'user id', 'Cont_start'], axis=1)\n",
    "\n",
    "# plot top 10 car makes\n",
    "car_make_counts = df3['car'].value_counts().head(10)\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.barplot(x=car_make_counts.index, y=car_make_counts.values, palette='Blues_r')\n",
    "plt.title('Top 10 Car Makes')\n",
    "plt.xlabel('Car Make')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "\n",
    "# plot car classes\n",
    "car_class_counts = df3['car_class'].value_counts()\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.barplot(x=car_class_counts.index, y=car_class_counts.values, palette='Blues_r')\n",
    "plt.title('Car Class Distribution')\n",
    "plt.xlabel('Car Class')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "\n",
    "# plot group distribution\n",
    "group_counts = df3['group'].value_counts()\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.barplot(x=group_counts.index, y=group_counts.values, palette='Blues_r')\n",
    "plt.title('Group Distribution')\n",
    "plt.xlabel('Group')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "\n",
    "# plot age distribution for targets\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.histplot(data=df3, x='d_age', hue='Target', kde=True, palette='Blues_r')\n",
    "plt.title('Age Distribution for Targets')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "# separate the target variable from the features\n",
    "y = df3['Target']\n",
    "X = df3.drop('Target', axis=1)\n",
    "\n",
    "# one-hot-encode categorical variables\n",
    "X = pd.get_dummies(X, columns=['car', 'year', 'month', 'Region', 'Root', 'gender ', 'car_class'])\n",
    "\n",
    "# fill any missing values with 0\n",
    "X.fillna(0, inplace=True)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "stratified_split = StratifiedShuffleSplit(n_splits=1, test_size=0.20, random_state=0)\n",
    "for train_index, test_index in stratified_split.split(X, y):\n",
    "    strat_train_X = X.iloc[train_index]\n",
    "    strat_train_y = y.iloc[train_index]\n",
    "    strat_test_X = X.iloc[test_index]\n",
    "    strat_test_y = y.iloc[test_index]\n",
    "\n",
    "# Create a scaler object\n",
    "scaler = StandardScaler() \n",
    "\n",
    "# Fit the scaler on the training set\n",
    "scaler.fit(strat_train_X)\n",
    "\n",
    "# Scale the training set\n",
    "X_train_st = scaler.transform(strat_train_X)\n",
    "\n",
    "# Scale the testing set using the same scaler\n",
    "X_test_st = scaler.transform(strat_test_X)    \n",
    "\n",
    "#XGBooster\n",
    "\n",
    "# Define the parameter grid for XGBoost\n",
    "param_grid_xgb = {\n",
    "    \"learning_rate\": [0.2],\n",
    "    \"max_depth\": [50],\n",
    "    \"n_estimators\": [20],\n",
    "    \"subsample\": [0.5],\n",
    "    \"colsample_bytree\": [1.0],\n",
    "    \"gamma\": [0.1],\n",
    "    \"scale_pos_weight\":[5]\n",
    "}\n",
    "\n",
    "# Create a XGBoost classifier and perform a grid search to find the best hyperparameters\n",
    "model = XGBClassifier()\n",
    "grid_search = GridSearchCV(model, param_grid_xgb, cv=5, scoring='recall')\n",
    "grid_search.fit(X_train_st, strat_train_y)\n",
    "\n",
    "# Print the results of the grid search\n",
    "print(grid_search)\n",
    "\n",
    "expected_y  = strat_test_y\n",
    "predicted_y = grid_search.predict(X_test_st)\n",
    "\n",
    "acc_xgb=accuracy_score(expected_y,predicted_y)\n",
    "acc_xgb=acc_xgb*100\n",
    "acc_xgb\n",
    "\n",
    "print(metrics.classification_report(expected_y, predicted_y))\n",
    "print(metrics.confusion_matrix(expected_y, predicted_y))\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(expected_y, predicted_y)\n",
    "kappa = cohen_kappa_score(expected_y, predicted_y)\n",
    "# Compute area under the curve (AUC)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "\n",
    "\n",
    "# Plot ROC curve and kappa score\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (AUC = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('XGB (ROC) Curve\\nCohen\\'s kappa = %0.2f' % kappa)\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "#DT\n",
    "\n",
    "param_grid_dtc={'criterion':['gini'],\n",
    "                'max_depth':[1000],\n",
    "                'min_samples_split':[200],\n",
    "                'min_samples_leaf': [100],\n",
    "                'max_features': ['auto'],\n",
    "                'splitter': ['best'],\n",
    "                'max_leaf_nodes': [ 1000],\n",
    "                'min_impurity_decrease': [0.0],\n",
    "                'class_weight': [ 'balanced']}\n",
    "\n",
    "# Create Decision Tree model\n",
    "clf = DecisionTreeClassifier()\n",
    "grid_search_dtc = GridSearchCV(estimator=clf, param_grid=param_grid_dtc, cv=10,scoring='recall')\n",
    "grid_search_dtc.fit(X_train_st, strat_train_y)\n",
    "print(grid_search_dtc)\n",
    "\n",
    "expected_y_dtc  = strat_test_y\n",
    "predicted_y_dtc = grid_search_dtc.predict(X_test_st)\n",
    "\n",
    "acc_dtc=accuracy_score(expected_y_dtc,predicted_y_dtc)\n",
    "acc_dtc=acc_dtc*100\n",
    "acc_dtc\n",
    "\n",
    "\n",
    "print(metrics.classification_report(expected_y_dtc,predicted_y_dtc))\n",
    "print(metrics.confusion_matrix(expected_y_dtc,predicted_y_dtc))\n",
    "\n",
    "fpr1, tpr1, thresholds1 = roc_curve(expected_y_dtc,predicted_y_dtc)\n",
    "kappa1 = cohen_kappa_score(expected_y_dtc,predicted_y_dtc)\n",
    "# Compute area under the curve (AUC)\n",
    "roc_auc1 = auc(fpr1, tpr1)\n",
    "\n",
    "\n",
    "\n",
    "# Plot ROC curve and kappa score\n",
    "plt.figure()\n",
    "plt.plot(fpr1, tpr1, color='darkorange', lw=2, label='ROC curve (AUC = %0.2f)' % roc_auc1)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('DT (ROC) Curve\\nCohen\\'s kappa = %0.2f' % kappa1)\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "#RF\n",
    "\n",
    "param_grid_rf={'n_estimators':[100],\n",
    "               'max_depth':[45],\n",
    "               'min_samples_split':[50],\n",
    "               'min_samples_leaf': [20],\n",
    "               'max_features':['sqrt']}\n",
    "\n",
    "# Create Random Forest model\n",
    "rf_model=RandomForestClassifier()\n",
    "grid_search_rf=GridSearchCV(estimator=rf_model,param_grid=param_grid_rf,cv=10,scoring='recall')\n",
    "grid_search_rf.fit(X_train_st, strat_train_y)\n",
    "print(grid_search_rf)\n",
    "\n",
    "expected_y_rf  = strat_test_y\n",
    "predicted_y_rf = grid_search_rf.predict(X_test_st)\n",
    "\n",
    "acc_rf=accuracy_score(expected_y_rf,predicted_y_rf)\n",
    "acc_rf=acc_rf*100\n",
    "acc_rf\n",
    "\n",
    "\n",
    "print(metrics.classification_report(expected_y_rf,predicted_y_rf))\n",
    "print(metrics.confusion_matrix(expected_y_rf,predicted_y_rf))\n",
    "\n",
    "fpr2, tpr2, thresholds2 = roc_curve(expected_y_rf,predicted_y_rf)\n",
    "kappa2 = cohen_kappa_score(expected_y_rf,predicted_y_rf)\n",
    "# Compute area under the curve (AUC)\n",
    "roc_auc2 = auc(fpr2, tpr2)\n",
    "\n",
    "\n",
    "\n",
    "# Plot ROC curve and kappa score\n",
    "plt.figure()\n",
    "plt.plot(fpr2, tpr2, color='darkorange', lw=2, label='ROC curve (AUC = %0.2f)' % roc_auc2)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('RF (ROC) Curve\\nCohen\\'s kappa = %0.2f' % kappa2)\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "#LR\n",
    "\n",
    "hyperparameters = {\n",
    "    'penalty': ['l2'],\n",
    "    'C': [0.1],\n",
    "    'solver': [ 'sag'],\n",
    "    'max_iter': [200]\n",
    "}\n",
    "\n",
    "# Create Logistic Regression model\n",
    "lr_model = LogisticRegression()\n",
    "grid_search_lr = GridSearchCV(lr_model, hyperparameters, cv=5, verbose=0,scoring='recall')\n",
    "grid_search_lr.fit(X_train_st, strat_train_y)\n",
    "print(grid_search_lr)\n",
    "\n",
    "expected_y_lr  = strat_test_y\n",
    "predicted_y_lr = grid_search_lr.predict(X_test_st)\n",
    "\n",
    "acc_lr=accuracy_score(expected_y_lr,predicted_y_lr)\n",
    "acc_lr=acc_lr*100\n",
    "acc_lr\n",
    "\n",
    "print(metrics.classification_report(expected_y_lr,predicted_y_lr))\n",
    "print(metrics.confusion_matrix(expected_y_lr,predicted_y_lr))\n",
    "\n",
    "fpr3, tpr3, thresholds3 = roc_curve(expected_y_lr,predicted_y_lr)\n",
    "kappa3 = cohen_kappa_score(expected_y_lr,predicted_y_lr)\n",
    "# Compute area under the curve (AUC)\n",
    "roc_auc3 = auc(fpr3, tpr3)\n",
    "\n",
    "\n",
    "\n",
    "# Plot ROC curve and kappa score\n",
    "plt.figure()\n",
    "plt.plot(fpr3, tpr3, color='darkorange', lw=2, label='ROC curve (AUC = %0.2f)' % roc_auc3)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('LR (ROC) Curve\\nCohen\\'s kappa = %0.2f' % kappa3)\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "#ANN\n",
    "\n",
    "\n",
    "# define the neural network model architecture\n",
    "classifier = Sequential()\n",
    "classifier.add(Dense(units=350, kernel_initializer=\"uniform\", activation=\"relu\", input_dim=148))\n",
    "classifier.add(Dense(units = 160, kernel_initializer=\"uniform\", activation=\"relu\"))\n",
    "classifier.add(Dense(units = 1, kernel_initializer=\"uniform\", activation=\"sigmoid\"))\n",
    "\n",
    "# compile the model\n",
    "classifier.compile(optimizer = \"Adagrad\", loss = \"binary_crossentropy\", metrics=['Recall'])\n",
    "\n",
    "# train the model\n",
    "classifier.fit(X_train_st, strat_train_y, batch_size=64, epochs=45)\n",
    "\n",
    "# make predictions on the test set\n",
    "Y_predict = classifier.predict(X_test_st)\n",
    "expected_y_ann = strat_test_y\n",
    "Y_predict = (Y_predict > 0.5)\n",
    "\n",
    "print(metrics.classification_report(expected_y_ann,Y_predict))\n",
    "print(metrics.confusion_matrix(expected_y_ann,Y_predict))\n",
    "\n",
    "fpr4, tpr4, thresholds4 = roc_curve(expected_y_ann,Y_predict)\n",
    "kappa4 = cohen_kappa_score(expected_y_ann,Y_predict)\n",
    "# Compute area under the curve (AUC)\n",
    "roc_auc4 = auc(fpr4, tpr4)\n",
    "\n",
    "\n",
    "\n",
    "# Plot ROC curve and kappa score\n",
    "plt.figure()\n",
    "plt.plot(fpr4, tpr4, color='darkorange', lw=2, label='ROC curve (AUC = %0.2f)' % roc_auc4)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ANN (ROC) Curve\\nCohen\\'s kappa = %0.2f' % kappa4)\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "xgb_report = metrics.classification_report(expected_y, predicted_y, output_dict=True)\n",
    "dtc_report = metrics.classification_report(expected_y_dtc,predicted_y_dtc, output_dict=True)\n",
    "rf_report =metrics.classification_report(expected_y_rf,predicted_y_rf, output_dict=True)\n",
    "lr_report = metrics.classification_report(expected_y_lr,predicted_y_lr, output_dict=True)\n",
    "ann_report = metrics.classification_report(expected_y_ann,Y_predict, output_dict=True)\n",
    "\n",
    "kappa = cohen_kappa_score(expected_y, predicted_y)\n",
    "kappa1 = cohen_kappa_score(expected_y_dtc,predicted_y_dtc)\n",
    "kappa2 = cohen_kappa_score(expected_y_rf,predicted_y_rf)\n",
    "kappa3 = cohen_kappa_score(expected_y_lr,predicted_y_lr)\n",
    "kappa4 = cohen_kappa_score(expected_y_ann,Y_predict)\n",
    "\n",
    "\n",
    "# calculate AUC-ROC score for each model\n",
    "xgb_auc = metrics.roc_auc_score(expected_y, predicted_y)\n",
    "dtc_auc = metrics.roc_auc_score(expected_y_dtc, predicted_y_dtc)\n",
    "rf_auc = metrics.roc_auc_score(expected_y_rf, predicted_y_rf)\n",
    "lr_auc = metrics.roc_auc_score(expected_y_lr, predicted_y_lr)\n",
    "ann_auc = metrics.roc_auc_score(expected_y_ann, Y_predict)\n",
    "#svm_auc = metrics.roc_auc_score(expected_y_svm, predicted_y_svm)\n",
    "\n",
    "# create a table with classification report and confusion matrix for each model\n",
    "table_data = {\n",
    "    'Model': ['XGBoost', 'Decision Tree', 'Random Forest', 'Logistic Regression', 'ANN'],\n",
    "    'Accuracy': [xgb_report['accuracy'], dtc_report['accuracy'], rf_report['accuracy'], lr_report['accuracy'], ann_report['accuracy']],\n",
    "    'AUC':[xgb_auc,dtc_auc,rf_auc,lr_auc,ann_auc],\n",
    "    'Kappa':[kappa,kappa1,kappa2,kappa3,kappa4],\n",
    "    'Precision': [xgb_report['macro avg']['precision'], dtc_report['macro avg']['precision'], rf_report['macro avg']['precision'], lr_report['macro avg']['precision'], ann_report['macro avg']['precision']],\n",
    "    'Recall': [xgb_report['macro avg']['recall'], dtc_report['macro avg']['recall'], rf_report['macro avg']['recall'], lr_report['macro avg']['recall'], ann_report['macro avg']['recall']],\n",
    "    'F1-score': [xgb_report['macro avg']['f1-score'], dtc_report['macro avg']['f1-score'], rf_report['macro avg']['f1-score'], lr_report['macro avg']['f1-score'], ann_report['macro avg']['f1-score']]\n",
    "    \n",
    "}\n",
    "\n",
    "# create Pandas DataFrame from the table data\n",
    "table_df = pd.DataFrame(table_data)\n",
    "\n",
    "# print the table\n",
    "print(table_df)\n",
    "\n",
    "\n",
    "# Define data for each model\n",
    "models = [\n",
    "    {'name': 'XGB', 'expected': expected_y, 'predicted': predicted_y},\n",
    "    {'name': 'DT', 'expected': expected_y_dtc, 'predicted': predicted_y_dtc},\n",
    "    {'name': 'RF', 'expected': expected_y_rf, 'predicted': predicted_y_rf},\n",
    "    {'name': 'LR', 'expected': expected_y_lr, 'predicted': predicted_y_lr},\n",
    "    {'name': 'ANN', 'expected': expected_y_ann, 'predicted': Y_predict},\n",
    "]\n",
    "\n",
    "# Define subplots\n",
    "fig, axes = plt.subplots(nrows=1, ncols=len(models), figsize=(20, 5))\n",
    "\n",
    "# Loop through each model and plot its ROC curve\n",
    "for i, model in enumerate(models):\n",
    "    # Calculate fpr, tpr, and thresholds\n",
    "    fpr, tpr, thresholds = roc_curve(model['expected'], model['predicted'])\n",
    "    # Calculate AUC and kappa score\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    kappa = cohen_kappa_score(model['expected'], model['predicted'])\n",
    "    # Plot ROC curve and kappa score\n",
    "    axes[i].plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (AUC = %0.2f)' % roc_auc)\n",
    "    axes[i].plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    axes[i].set_xlim([0.0, 1.0])\n",
    "    axes[i].set_ylim([0.0, 1.05])\n",
    "    axes[i].set_xlabel('False Positive Rate')\n",
    "    axes[i].set_ylabel('True Positive Rate')\n",
    "    axes[i].set_title('%s (ROC) Curve\\nCohen\\'s kappa = %0.2f' % (model['name'], kappa))\n",
    "    axes[i].legend(loc=\"lower right\")\n",
    "\n",
    "# Display the figure\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
